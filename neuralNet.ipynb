{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_secret_garden.txt\n",
      "get_book(): Text obtained from file 'books/book_secret_garden.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_eye_of_apollo.txt\n",
      "get_book(): Text obtained from file 'books/book_eye_of_apollo.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_soul_of_schoolboy.txt\n",
      "get_book(): Text obtained from file 'books/book_soul_of_schoolboy.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_the_sins_of_prince_saradine.txt\n",
      "get_book(): Text obtained from file 'books/book_the_sins_of_prince_saradine.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_sign_of_the_broken_sword.txt\n",
      "get_book(): Text obtained from file 'books/book_sign_of_the_broken_sword.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_the_hammer_of_god.txt\n",
      "get_book(): Text obtained from file 'books/book_the_hammer_of_god.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_the_flying_stars.txt\n",
      "get_book(): Text obtained from file 'books/book_the_flying_stars.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_fad_of_the_fisherman.txt\n",
      "get_book(): Text obtained from file 'books/book_fad_of_the_fisherman.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_the_blue_cross.txt\n",
      "get_book(): Text obtained from file 'books/book_the_blue_cross.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_the_wrong_shape.txt\n",
      "get_book(): Text obtained from file 'books/book_the_wrong_shape.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_the_queer_feet.txt\n",
      "get_book(): Text obtained from file 'books/book_the_queer_feet.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_vanishing_prince.txt\n",
      "get_book(): Text obtained from file 'books/book_vanishing_prince.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_three_tools_of_death.txt\n",
      "get_book(): Text obtained from file 'books/book_three_tools_of_death.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_vengeance_of_the_statue.txt\n",
      "get_book(): Text obtained from file 'books/book_vengeance_of_the_statue.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_temple_of_silence.txt\n",
      "get_book(): Text obtained from file 'books/book_temple_of_silence.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_bottomless_well.txt\n",
      "get_book(): Text obtained from file 'books/book_bottomless_well.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_face_in_the_target.txt\n",
      "get_book(): Text obtained from file 'books/book_face_in_the_target.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[__init__]: Initializing book from file: books/book_hole_in_the_wall.txt\n",
      "get_book(): Text obtained from file 'books/book_hole_in_the_wall.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Start of Project Gutenberg header not found.\n",
      "Warning: End of Project Gutenberg footer not found.\n",
      "/home/tnitzsch/conda/envs/nlp/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.7249 - loss: 0.6460 - val_accuracy: 0.5652 - val_loss: 0.6766\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8115 - loss: 0.6023 - val_accuracy: 0.5652 - val_loss: 0.6508\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8209 - loss: 0.5783 - val_accuracy: 0.5652 - val_loss: 0.6277\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7845 - loss: 0.5528 - val_accuracy: 0.6957 - val_loss: 0.6118\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8161 - loss: 0.5082 - val_accuracy: 0.6957 - val_loss: 0.6019\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8008 - loss: 0.5003 - val_accuracy: 0.6522 - val_loss: 0.5879\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8249 - loss: 0.4866 - val_accuracy: 0.6522 - val_loss: 0.5769\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8212 - loss: 0.4514 - val_accuracy: 0.6957 - val_loss: 0.5733\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8056 - loss: 0.4530 - val_accuracy: 0.6957 - val_loss: 0.5688\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8250 - loss: 0.4500 - val_accuracy: 0.6957 - val_loss: 0.5643\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8297 - loss: 0.4165 - val_accuracy: 0.6957 - val_loss: 0.5673\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8952 - loss: 0.3750 - val_accuracy: 0.6957 - val_loss: 0.5715\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8805 - loss: 0.3750 - val_accuracy: 0.6957 - val_loss: 0.5743\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8727 - loss: 0.3718 - val_accuracy: 0.6957 - val_loss: 0.5669\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8449 - loss: 0.3908 - val_accuracy: 0.6957 - val_loss: 0.5588\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8661 - loss: 0.3663 - val_accuracy: 0.6957 - val_loss: 0.5578\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8851 - loss: 0.3469 - val_accuracy: 0.6957 - val_loss: 0.5551\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9038 - loss: 0.3315 - val_accuracy: 0.6957 - val_loss: 0.5514\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8947 - loss: 0.3300 - val_accuracy: 0.6957 - val_loss: 0.5551\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8942 - loss: 0.3279 - val_accuracy: 0.6957 - val_loss: 0.5553\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8638 - loss: 0.3333 - val_accuracy: 0.6957 - val_loss: 0.5524\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8942 - loss: 0.2982 - val_accuracy: 0.6957 - val_loss: 0.5541\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8977 - loss: 0.3059 - val_accuracy: 0.6957 - val_loss: 0.5540\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9003 - loss: 0.2807 - val_accuracy: 0.6957 - val_loss: 0.5556\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9072 - loss: 0.2711 - val_accuracy: 0.6957 - val_loss: 0.5525\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8842 - loss: 0.2801 - val_accuracy: 0.6957 - val_loss: 0.5516\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8876 - loss: 0.2743 - val_accuracy: 0.6957 - val_loss: 0.5657\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9189 - loss: 0.2568 - val_accuracy: 0.6957 - val_loss: 0.5637\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8954 - loss: 0.2636 - val_accuracy: 0.6522 - val_loss: 0.5619\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9197 - loss: 0.2317 - val_accuracy: 0.6522 - val_loss: 0.5659\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9280 - loss: 0.2095 - val_accuracy: 0.6522 - val_loss: 0.5808\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9171 - loss: 0.2281 - val_accuracy: 0.6522 - val_loss: 0.5834\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9275 - loss: 0.2031 - val_accuracy: 0.6522 - val_loss: 0.5873\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9548 - loss: 0.2013 - val_accuracy: 0.6522 - val_loss: 0.5980\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9590 - loss: 0.1847 - val_accuracy: 0.6522 - val_loss: 0.5984\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9497 - loss: 0.1901 - val_accuracy: 0.6522 - val_loss: 0.6078\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9404 - loss: 0.2042 - val_accuracy: 0.6522 - val_loss: 0.6162\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9569 - loss: 0.1683 - val_accuracy: 0.6522 - val_loss: 0.6276\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9252 - loss: 0.1994 - val_accuracy: 0.6522 - val_loss: 0.6378\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9685 - loss: 0.1496 - val_accuracy: 0.6522 - val_loss: 0.6528\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9620 - loss: 0.1493 - val_accuracy: 0.6522 - val_loss: 0.6687\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9469 - loss: 0.1538 - val_accuracy: 0.6522 - val_loss: 0.6702\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9642 - loss: 0.1438 - val_accuracy: 0.6522 - val_loss: 0.6772\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9538 - loss: 0.1445 - val_accuracy: 0.6522 - val_loss: 0.6871\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9438 - loss: 0.1476 - val_accuracy: 0.6522 - val_loss: 0.7025\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9459 - loss: 0.1455 - val_accuracy: 0.6522 - val_loss: 0.7235\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9785 - loss: 0.1195 - val_accuracy: 0.6522 - val_loss: 0.7436\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9806 - loss: 0.1180 - val_accuracy: 0.6522 - val_loss: 0.7508\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 0.1135 - val_accuracy: 0.6957 - val_loss: 0.7521\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9680 - loss: 0.1180 - val_accuracy: 0.6957 - val_loss: 0.7650\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82        20\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.70        23\n",
      "   macro avg       0.42      0.40      0.41        23\n",
      "weighted avg       0.73      0.70      0.71        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from Book_module.Book import Book\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Initialize an empty list to store character data\n",
    "character_data = []\n",
    "\n",
    "# Path to the folder containing your stories\n",
    "stories_folder = 'books'\n",
    "\n",
    "# List all story files\n",
    "story_files = [f for f in os.listdir(stories_folder) if f.endswith('.txt')]\n",
    "\n",
    "# Dictionary mapping story filenames to perpetrators\n",
    "story_perpetrators = {\n",
    "    'book_bottomless_well.txt': 'Harrison',\n",
    "    'book_eye_of_apollo.txt': 'Kevin',\n",
    "    'book_face_in_the_target.txt': 'Jenkins',\n",
    "    'book_fad_of_the_fisherman.txt': 'Merivale',\n",
    "    'book_hole_in_the_wall.txt': 'Haddow',\n",
    "    'book_secret_garden.txt': 'Valentin',\n",
    "    'book_sign_of_the_broken_sword.txt': 'Arthur',\n",
    "    'book_soul_of_schoolboy.txt': 'Morty',\n",
    "    'book_temple_of_silence.txt': 'Verner',\n",
    "    'book_the_blue_cross.txt': 'Hercule',\n",
    "    'book_the_flying_stars.txt': 'Hercule',\n",
    "    'book_the_hammer_of_god.txt': 'Wilfred',\n",
    "    'book_the_queer_feet.txt': 'Hercule',\n",
    "    'book_the_sins_of_prince_saradine.txt': 'Saradine',\n",
    "    'book_the_wrong_shape.txt': 'Harris',\n",
    "    'book_three_tools_of_death.txt': 'Aaron',\n",
    "    'book_vanishing_prince.txt': 'Wilson',\n",
    "    'book_vengeance_of_the_statue.txt': 'Horne'\n",
    "}\n",
    "\n",
    "# Process each story and extract features\n",
    "for story_file in story_files:\n",
    "    file_path = os.path.join(stories_folder, story_file)\n",
    "    book = Book(file_path)\n",
    "    book.pre_process()\n",
    "    book.feature_extraction()\n",
    "    \n",
    "    # Get the perpetrator for this story\n",
    "    perpetrator = story_perpetrators.get(story_file)\n",
    "    if perpetrator is None:\n",
    "        print(f\"No perpetrator found for {story_file}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    for character in book.names:\n",
    "        # Character-specific features\n",
    "        mention_count = book.character_mentions_all.get(character, 0)\n",
    "        first_mention = book.character_mentions_first.get(character, -1)\n",
    "        sentiment = book.character_sentiments.get(character, 0)\n",
    "        \n",
    "        # Rank of the character by mentions\n",
    "        mentions_sorted = sorted(book.character_mentions_all.items(), key=lambda x: x[1], reverse=True)\n",
    "        char_rank = next((rank for rank, (name, _) in enumerate(mentions_sorted, 1) if name == character), None)\n",
    "        \n",
    "        # Proximity features\n",
    "        proximity_score = sum(count for (char1, char2), count in book.character_proximity.items() if character in (char1, char2))\n",
    "        \n",
    "        # Label: 1 if this character is the perpetrator, 0 otherwise\n",
    "        label = 1 if character == perpetrator else 0\n",
    "\n",
    "        # New Feature: Plot Phase of First Mention\n",
    "        first_mention_phase = None\n",
    "        if hasattr(book, 'plot_structure'):\n",
    "            for phase, (start_idx, end_idx) in book.plot_structure.items():\n",
    "                if first_mention >= start_idx and first_mention <= end_idx:\n",
    "                    first_mention_phase = phase\n",
    "                    break\n",
    "        if first_mention_phase is None:\n",
    "            first_mention_phase = 'Unknown'\n",
    "\n",
    "        # One-hot encode the plot phase\n",
    "        plot_phases = ['Exposition', 'Rising Action', 'Climax', 'Falling Action', 'Resolution', 'Unknown']\n",
    "        plot_phase_features = {f'First_Mention_{phase.replace(\" \", \"_\")}': int(first_mention_phase == phase) for phase in plot_phases}\n",
    "\n",
    "        # New Feature: Mentions per Plot Phase\n",
    "        mentions_per_phase = {phase: 0 for phase in plot_phases}\n",
    "\n",
    "        # Map sentence indices to plot phases\n",
    "        sentence_plot_phases = {}\n",
    "        if hasattr(book, 'plot_structure'):\n",
    "            for phase, (start_idx, end_idx) in book.plot_structure.items():\n",
    "                for idx in range(start_idx, end_idx + 1):\n",
    "                    sentence_plot_phases[idx] = phase\n",
    "        else:\n",
    "            for idx in range(len(book.sentences)):\n",
    "                sentence_plot_phases[idx] = 'Unknown'\n",
    "\n",
    "        # Count mentions per plot phase\n",
    "        for idx, sentence in enumerate(book.sentences):\n",
    "            phase = sentence_plot_phases.get(idx, 'Unknown')\n",
    "            if character in sentence:\n",
    "                mentions_per_phase[phase] += 1\n",
    "\n",
    "        # Add mentions per phase to the features\n",
    "        total_mentions = sum(mentions_per_phase.values())\n",
    "        if total_mentions > 0:\n",
    "            mentions_proportion = {f'Mentions_{phase.replace(\" \", \"_\")}_Proportion': mentions_per_phase[phase] / total_mentions for phase in plot_phases}\n",
    "        else:\n",
    "            mentions_proportion = {f'Mentions_{phase.replace(\" \", \"_\")}_Proportion': 0 for phase in plot_phases}\n",
    "        \n",
    "        # Prepare the row data\n",
    "        row = {\n",
    "            'Story': story_file,\n",
    "            'Character': character,\n",
    "            'Label': label,\n",
    "            'Mention_Count': mention_count,\n",
    "            'First_Mention': first_mention,\n",
    "            'Sentiment': sentiment,\n",
    "            'Rank': char_rank,\n",
    "            'Proximity_Score': proximity_score,\n",
    "        }\n",
    "\n",
    "        # Add the plot phase features\n",
    "        row.update(plot_phase_features)\n",
    "        row.update(mentions_proportion)\n",
    "        \n",
    "        character_data.append(row)\n",
    "\n",
    "# Create the DataFrame\n",
    "character_df = pd.DataFrame(character_data)\n",
    "\n",
    "# Handle any missing values\n",
    "character_df.fillna(0, inplace=True)\n",
    "\n",
    "# Define the feature list\n",
    "features = [\n",
    "    'Mention_Count', 'First_Mention', 'Sentiment', 'Rank', 'Proximity_Score',\n",
    "    'First_Mention_Exposition', 'First_Mention_Rising_Action', 'First_Mention_Climax',\n",
    "    'First_Mention_Falling_Action', 'First_Mention_Resolution', 'First_Mention_Unknown',\n",
    "    'Mentions_Exposition_Proportion', 'Mentions_Rising_Action_Proportion',\n",
    "    'Mentions_Climax_Proportion', 'Mentions_Falling_Action_Proportion',\n",
    "    'Mentions_Resolution_Proportion', 'Mentions_Unknown_Proportion',\n",
    "]\n",
    "\n",
    "# Prepare the dataset\n",
    "X = character_df[features]\n",
    "y = character_df['Label']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the neural network model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_resampled),\n",
    "    y=y_train_resampled\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_resampled,\n",
    "    y_train_resampled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
