{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 07:31:35.519248: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-28 07:31:35.653526: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 07:31:36.483242: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-28 07:31:37.084114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730115097.452535   25373 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730115097.537604   25373 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-28 07:31:38.698828: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/tnitzsch/conda/envs/nlp/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-28 07:36:46.210322: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.6408 - loss: 0.6489 - val_accuracy: 0.4783 - val_loss: 0.7034\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6942 - loss: 0.5966 - val_accuracy: 0.5652 - val_loss: 0.7000\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7547 - loss: 0.5496 - val_accuracy: 0.5652 - val_loss: 0.6984\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8239 - loss: 0.5012 - val_accuracy: 0.6087 - val_loss: 0.6925\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8373 - loss: 0.4785 - val_accuracy: 0.6522 - val_loss: 0.6751\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8238 - loss: 0.4776 - val_accuracy: 0.6522 - val_loss: 0.6580\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8445 - loss: 0.4330 - val_accuracy: 0.6522 - val_loss: 0.6466\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8427 - loss: 0.4277 - val_accuracy: 0.6522 - val_loss: 0.6358\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9139 - loss: 0.3774 - val_accuracy: 0.6522 - val_loss: 0.6326\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8639 - loss: 0.3898 - val_accuracy: 0.6087 - val_loss: 0.6218\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8621 - loss: 0.3687 - val_accuracy: 0.6087 - val_loss: 0.6218\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8747 - loss: 0.3522 - val_accuracy: 0.6087 - val_loss: 0.6245\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9003 - loss: 0.3284 - val_accuracy: 0.6087 - val_loss: 0.6328\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8825 - loss: 0.3570 - val_accuracy: 0.6087 - val_loss: 0.6300\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8799 - loss: 0.3345 - val_accuracy: 0.6522 - val_loss: 0.6244\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9046 - loss: 0.3060 - val_accuracy: 0.6522 - val_loss: 0.6280\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9141 - loss: 0.2782 - val_accuracy: 0.6522 - val_loss: 0.6364\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9315 - loss: 0.2724 - val_accuracy: 0.6522 - val_loss: 0.6420\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9262 - loss: 0.2484 - val_accuracy: 0.6522 - val_loss: 0.6481\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8932 - loss: 0.2816 - val_accuracy: 0.6522 - val_loss: 0.6390\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9266 - loss: 0.2520 - val_accuracy: 0.6522 - val_loss: 0.6400\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9293 - loss: 0.2434 - val_accuracy: 0.6522 - val_loss: 0.6548\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9067 - loss: 0.2511 - val_accuracy: 0.6522 - val_loss: 0.6502\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9266 - loss: 0.2382 - val_accuracy: 0.6522 - val_loss: 0.6647\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9335 - loss: 0.2407 - val_accuracy: 0.6522 - val_loss: 0.6672\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9296 - loss: 0.2140 - val_accuracy: 0.6522 - val_loss: 0.6812\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9123 - loss: 0.2153 - val_accuracy: 0.6522 - val_loss: 0.6788\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9170 - loss: 0.2248 - val_accuracy: 0.6522 - val_loss: 0.6743\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9339 - loss: 0.2011 - val_accuracy: 0.6522 - val_loss: 0.6848\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9287 - loss: 0.2193 - val_accuracy: 0.6522 - val_loss: 0.6909\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9200 - loss: 0.1921 - val_accuracy: 0.6522 - val_loss: 0.7027\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9617 - loss: 0.1649 - val_accuracy: 0.6522 - val_loss: 0.7150\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9391 - loss: 0.1815 - val_accuracy: 0.6522 - val_loss: 0.7127\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9594 - loss: 0.1670 - val_accuracy: 0.6522 - val_loss: 0.7160\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9516 - loss: 0.1542 - val_accuracy: 0.6522 - val_loss: 0.7307\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9490 - loss: 0.1642 - val_accuracy: 0.6522 - val_loss: 0.7410\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9486 - loss: 0.1617 - val_accuracy: 0.6522 - val_loss: 0.7532\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9607 - loss: 0.1391 - val_accuracy: 0.6522 - val_loss: 0.7681\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9585 - loss: 0.1436 - val_accuracy: 0.6522 - val_loss: 0.7689\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9407 - loss: 0.1500 - val_accuracy: 0.6522 - val_loss: 0.7673\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.1004 - val_accuracy: 0.6522 - val_loss: 0.7924\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9685 - loss: 0.1284 - val_accuracy: 0.6522 - val_loss: 0.8006\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9685 - loss: 0.1163 - val_accuracy: 0.6957 - val_loss: 0.7999\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9684 - loss: 0.1116 - val_accuracy: 0.6957 - val_loss: 0.8086\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9850 - loss: 0.0882 - val_accuracy: 0.6957 - val_loss: 0.8272\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9654 - loss: 0.1024 - val_accuracy: 0.6957 - val_loss: 0.8197\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9784 - loss: 0.0989 - val_accuracy: 0.6957 - val_loss: 0.8175\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9671 - loss: 0.0957 - val_accuracy: 0.6957 - val_loss: 0.8332\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0846 - val_accuracy: 0.6957 - val_loss: 0.8442\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9814 - loss: 0.0922 - val_accuracy: 0.6957 - val_loss: 0.8614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82        20\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.70        23\n",
      "   macro avg       0.42      0.40      0.41        23\n",
      "weighted avg       0.73      0.70      0.71        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from Book_module.Book import Book\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "character_data = []\n",
    "stories_folder = 'books'\n",
    "story_files = [f for f in os.listdir(stories_folder) if f.endswith('.txt')]\n",
    "\n",
    "#Dictionary mapping story filenames to perpetrators\n",
    "story_perpetrators = {\n",
    "    'book_bottomless_well.txt': 'Harrison',\n",
    "    'book_eye_of_apollo.txt': 'Kevin',\n",
    "    'book_face_in_the_target.txt': 'Jenkins',\n",
    "    'book_fad_of_the_fisherman.txt': 'Merivale',\n",
    "    'book_hole_in_the_wall.txt': 'Haddow',\n",
    "    'book_secret_garden.txt': 'Valentin',\n",
    "    'book_sign_of_the_broken_sword.txt': 'Arthur',\n",
    "    'book_soul_of_schoolboy.txt': 'Morty',\n",
    "    'book_temple_of_silence.txt': 'Verner',\n",
    "    'book_the_blue_cross.txt': 'Hercule',\n",
    "    'book_the_flying_stars.txt': 'Hercule',\n",
    "    'book_the_hammer_of_god.txt': 'Wilfred',\n",
    "    'book_the_queer_feet.txt': 'Hercule',\n",
    "    'book_the_sins_of_prince_saradine.txt': 'Saradine',\n",
    "    'book_the_wrong_shape.txt': 'Harris',\n",
    "    'book_three_tools_of_death.txt': 'Aaron',\n",
    "    'book_vanishing_prince.txt': 'Wilson',\n",
    "    'book_vengeance_of_the_statue.txt': 'Horne'\n",
    "}\n",
    "\n",
    "#Process each story and extract features\n",
    "for story_file in story_files:\n",
    "    file_path = os.path.join(stories_folder, story_file)\n",
    "    book = Book(file_path)\n",
    "    book.pre_process()\n",
    "    book.feature_extraction()\n",
    "    \n",
    "    #Get the perp for this story\n",
    "    perpetrator = story_perpetrators.get(story_file)\n",
    "    if perpetrator is None:\n",
    "        print(f\"No perpetrator found for {story_file}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    for character in book.names:\n",
    "        #Character-specific features\n",
    "        mention_count = book.character_mentions_all.get(character, 0)\n",
    "        first_mention = book.character_mentions_first.get(character, -1)\n",
    "        sentiment = book.character_sentiments.get(character, 0)\n",
    "        \n",
    "        #Rank of the character by mentions\n",
    "        mentions_sorted = sorted(book.character_mentions_all.items(), key=lambda x: x[1], reverse=True)\n",
    "        char_rank = next((rank for rank, (name, _) in enumerate(mentions_sorted, 1) if name == character), None)\n",
    "        \n",
    "        #Proximity features\n",
    "        proximity_score = sum(count for (char1, char2), count in book.character_proximity.items() if character in (char1, char2))\n",
    "        \n",
    "        #Label 1 if this character is the perp, 0 otherwise\n",
    "        label = 1 if character == perpetrator else 0\n",
    "\n",
    "        #Plot phase of first mention\n",
    "        first_mention_phase = None\n",
    "        if hasattr(book, 'plot_structure'):\n",
    "            for phase, (start_idx, end_idx) in book.plot_structure.items():\n",
    "                if first_mention >= start_idx and first_mention <= end_idx:\n",
    "                    first_mention_phase = phase\n",
    "                    break\n",
    "        if first_mention_phase is None:\n",
    "            first_mention_phase = 'Unknown'\n",
    "\n",
    "        #One-hot encode the plot phase\n",
    "        plot_phases = ['Exposition', 'Rising Action', 'Climax', 'Falling Action', 'Resolution', 'Unknown']\n",
    "        plot_phase_features = {f'First_Mention_{phase.replace(\" \", \"_\")}': int(first_mention_phase == phase) for phase in plot_phases}\n",
    "\n",
    "        #Mentions per plot phase\n",
    "        mentions_per_phase = {phase: 0 for phase in plot_phases}\n",
    "\n",
    "        #Map sentence indices to plot phases\n",
    "        sentence_plot_phases = {}\n",
    "        if hasattr(book, 'plot_structure'):\n",
    "            for phase, (start_idx, end_idx) in book.plot_structure.items():\n",
    "                for idx in range(start_idx, end_idx + 1):\n",
    "                    sentence_plot_phases[idx] = phase\n",
    "        else:\n",
    "            for idx in range(len(book.sentences)):\n",
    "                sentence_plot_phases[idx] = 'Unknown'\n",
    "\n",
    "        #Count mentions per plot phase\n",
    "        for idx, sentence in enumerate(book.sentences):\n",
    "            phase = sentence_plot_phases.get(idx, 'Unknown')\n",
    "            if character in sentence:\n",
    "                mentions_per_phase[phase] += 1\n",
    "\n",
    "        #Add mentions per phase to the features\n",
    "        total_mentions = sum(mentions_per_phase.values())\n",
    "        if total_mentions > 0:\n",
    "            mentions_proportion = {f'Mentions_{phase.replace(\" \", \"_\")}_Proportion': mentions_per_phase[phase] / total_mentions for phase in plot_phases}\n",
    "        else:\n",
    "            mentions_proportion = {f'Mentions_{phase.replace(\" \", \"_\")}_Proportion': 0 for phase in plot_phases}\n",
    "        \n",
    "        #Prepare the row data\n",
    "        row = {\n",
    "            'Story': story_file,\n",
    "            'Character': character,\n",
    "            'Label': label,\n",
    "            'Mention_Count': mention_count,\n",
    "            'First_Mention': first_mention,\n",
    "            'Sentiment': sentiment,\n",
    "            'Rank': char_rank,\n",
    "            'Proximity_Score': proximity_score,\n",
    "        }\n",
    "\n",
    "        #Add the plot phase features\n",
    "        row.update(plot_phase_features)\n",
    "        row.update(mentions_proportion)\n",
    "        \n",
    "        character_data.append(row)\n",
    "\n",
    "character_df = pd.DataFrame(character_data)\n",
    "character_df.fillna(0, inplace=True)\n",
    "\n",
    "features = [\n",
    "    'Mention_Count', 'First_Mention', 'Sentiment', 'Rank', 'Proximity_Score',\n",
    "    'First_Mention_Exposition', 'First_Mention_Rising_Action', 'First_Mention_Climax',\n",
    "    'First_Mention_Falling_Action', 'First_Mention_Resolution', 'First_Mention_Unknown',\n",
    "    'Mentions_Exposition_Proportion', 'Mentions_Rising_Action_Proportion',\n",
    "    'Mentions_Climax_Proportion', 'Mentions_Falling_Action_Proportion',\n",
    "    'Mentions_Resolution_Proportion', 'Mentions_Unknown_Proportion',\n",
    "]\n",
    "\n",
    "#Prepare the dataset\n",
    "x = character_df[features]\n",
    "y = character_df['Label']\n",
    "\n",
    "#Feature scaling\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "#Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "#Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "#Define the NN\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_resampled),\n",
    "    y=y_train_resampled\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "#Train the model\n",
    "history = model.fit(\n",
    "    X_train_resampled,\n",
    "    y_train_resampled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#Evaluate the model\n",
    "y_pred_prob = model.predict(x_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
